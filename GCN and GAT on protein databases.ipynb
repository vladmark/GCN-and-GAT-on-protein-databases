{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladmark/graph-convolutional-networks-/blob/main/GCN%20and%20GAT%20on%20protein%20databases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3TmAZCGWHYS"
      },
      "source": [
        "# 0.Prequisitories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6oYy53fVKKY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaSiyShRVNpm"
      },
      "source": [
        "! pip install torchviz\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import json\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from sklearn import preprocessing\n",
        "import torch.nn.functional as F\n",
        "import torchviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V7UImsUVU1U"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(1)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIURlC-TQmgv"
      },
      "source": [
        "**Basepath to project folder in drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCJqyw2JVWUa"
      },
      "source": [
        "basepath='/content/drive/My Drive/Proiect Deep/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAvZrVwWWM8r"
      },
      "source": [
        "#1. Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcA_Wl-OWPfp"
      },
      "source": [
        "def get_data_from_file(filename):\n",
        "    f=open(filename,\"r\")\n",
        "    data=json.load(f)\n",
        "    f.close()\n",
        "    return(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68UEdY6GWa7J"
      },
      "source": [
        "!ls \"$basepath\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tYzMvKGdY5o"
      },
      "source": [
        "From https://github.com/williamleif/GraphSAGE\n",
        "\n",
        "As input, at minimum the code requires that a --train_prefix option is specified which specifies the following data files:\n",
        "\n",
        "* train_prefix-G.json -- A networkx-specified json file describing the input graph. Nodes have 'val' and 'test' attributes specifying if they are a part of the validation and test sets, respectively.\n",
        "* train_prefix-id_map.json -- A json-stored dictionary mapping the graph node ids to consecutive integers.\n",
        "* train_prefix-class_map.json -- A json-stored dictionary mapping the graph node ids to classes.\n",
        "* train_prefix-feats.npy [optional] --- A numpy-stored array of node features; ordering given by id_map.json. Can be omitted and only identity features will be used.\n",
        "* train_prefix-walks.txt [optional] --- A text file specifying random walk co-occurrences (one pair per line) (*only for unsupervised version of graphsage)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDAmbZ20i46r"
      },
      "source": [
        "## Processing data and statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur3BlyyfWk7l"
      },
      "source": [
        "class_map=get_data_from_file(basepath+\"ppi-class_map.json\")\n",
        "feats=np.load(basepath+\"ppi-feats.npy\")\n",
        "G=get_data_from_file(basepath+\"ppi-G.json\")\n",
        "id_map=get_data_from_file(basepath+\"ppi-id_map.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4SATnxs3CNW"
      },
      "source": [
        "### Id map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2kd9qJT3UY8"
      },
      "source": [
        "id_map_list=id_map.items()\n",
        "print(id_map_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAQsnGmU3yIX"
      },
      "source": [
        "For this dataset `id_map` is not useful, node ids are already consecutive integers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK8s5gXaqEqH"
      },
      "source": [
        "### The graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKlWkoApdFaO"
      },
      "source": [
        "print(f'graph big structure keys: {G.keys()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ7kVYZNemKq"
      },
      "source": [
        "graph=G['graph']\n",
        "links=G['links']\n",
        "nodes=G['nodes']\n",
        "directed=G['directed']\n",
        "multigraph=G['multigraph']\n",
        "print(f'graph: {graph}')\n",
        "print(f'graph keys: {graph.keys()}')\n",
        "print(f'is it multigraph?: {multigraph}')\n",
        "print(f'is it directed graph?: {directed}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWyU1Y_be1CP"
      },
      "source": [
        "print(f'nodes datatype: {type(nodes)}')\n",
        "print(f'links datatype: {type(links)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxNrHEI3e5cj"
      },
      "source": [
        "print(f'first 5 nodes look like: {nodes[:5]}')\n",
        "print(f'first 5 links look like: {links[:5]}')\n",
        "print(f'we have {len(nodes)} nodes')\n",
        "print(f'we have {len(links)} links')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuKrskZjp-0s"
      },
      "source": [
        "### Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x3Wn7bVdAVF"
      },
      "source": [
        "class_map_list=[(node_id, class_map[node_id]) for node_id in class_map.keys()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOfnrQcQqf0T"
      },
      "source": [
        "print(f'{len(class_map_list)} nodes have labeled classes ({\"{:.0%}\".format(len(class_map_list)/len(nodes))} of all nodes)')\n",
        "no_classes=len(class_map_list[0][1])\n",
        "print(f'we have {no_classes} classes')\n",
        "class_freq=torch.mean(torch.FloatTensor(np.array([class_map_list[i][-1] for i in range(len(class_map_list))])) , dim=0)\n",
        "print(f'class frequencies are: {class_freq} (for check - of len {len(class_freq)})')\n",
        "print(f'average of class frequencies is: {torch.mean(class_freq)}')\n",
        "print(f'std of class frequencies is: {torch.std(class_freq)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hPjMZKSqBV8"
      },
      "source": [
        "### Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGnctyGbX4yb"
      },
      "source": [
        "print(f'we have {feats.shape[-1]} features')\n",
        "print(f'a feature sample: {feats[869]}')\n",
        "print(f'features have frequency: {np.mean(feats, axis=0)}')\n",
        "print(f'average of feature frequencies: {np.mean(np.mean(feats, axis=0))}')\n",
        "print(f'std of feature frequencies: {np.std(np.mean(feats, axis=0))}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TRTtFqCzt3_"
      },
      "source": [
        "zero_feats_row_indexes=[i for i in range(feats.shape[0]) if np.mean(feats[i])==0.]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e09qVS3d1Kv0"
      },
      "source": [
        "zero_classes_ids=[idx for (idx, idxlabels) in class_map.items() if np.mean(np.array(idxlabels)) != 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8zlGtFR4CTc"
      },
      "source": [
        "zero_classes_ids=[int(el) for el in zero_classes_ids]\n",
        "zero_feats_non_zero_classes=[i for i in zero_feats_row_indexes if i in zero_classes_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnDudmRC4VKu"
      },
      "source": [
        "print(f'{\"{:.2%}\".format(len(zero_feats_row_indexes)/feats.shape[0])} of all nodes have all features 0')\n",
        "print(f'{\"{:.2%}\".format(len(zero_feats_non_zero_classes)/feats.shape[0])} of all nodes have all features 0 but output classes non-zero')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcknWFdRy6Bw"
      },
      "source": [
        "feats=torch.FloatTensor(feats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DznVzlzrhJh0"
      },
      "source": [
        "## Train, val, test **ids** set construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kzbXQs_hRpv"
      },
      "source": [
        "train_ids=[nodes[i]['id'] for i in range(len(nodes)) if nodes[i]['test']==False and nodes[i]['val']==False]\n",
        "val_ids=[nodes[i]['id'] for i in range(len(nodes)) if nodes[i]['val']==True]\n",
        "test_ids=[nodes[i]['id'] for i in range(len(nodes)) if nodes[i]['test']==True]\n",
        "assert len(train_ids)+len(val_ids)+len(test_ids) == len(nodes), \"Seturile de train, validare, test nu dau tot datasetul\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjIAhjt0pr61"
      },
      "source": [
        "print(f'train is {\"{:.00%}\".format(len(train_ids)/len(nodes))} percent of dataset')\n",
        "print(f'validation is {\"{:.00%}\".format(len(val_ids)/len(nodes))} percent of dataset')\n",
        "print(f'test is {\"{:.00%}\".format(len(test_ids)/len(nodes))} percent of dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6vqJTHyoeq2"
      },
      "source": [
        "print(len(train_ids))\n",
        "print(len(val_ids))\n",
        "print(len(test_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYEo5ckWhG6d"
      },
      "source": [
        "## Link dict construction (a usable dictionary for GCN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzAK5bXFlIHZ"
      },
      "source": [
        "Construct a dict which has as\n",
        "* **node ids** as **keys**\n",
        "* **adjacent nodes** (as a **set**) as **values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgjQbMrif5sl"
      },
      "source": [
        "def construct_adjacency_dict(links, directed, always_self_loop=False ):\n",
        "  adj={}\n",
        "  for link in links:\n",
        "    source=link['source']\n",
        "    target=link['target']\n",
        "    if source not in adj.keys() and target not in adj.keys():\n",
        "      adj[source]=set([target])\n",
        "      if (not directed):\n",
        "        adj[target]=set([source])\n",
        "    elif source not in adj.keys():\n",
        "      adj[source]=set([target])\n",
        "      if (not directed):\n",
        "        adj[target]=adj[target] | set([source])\n",
        "    elif target not in adj.keys():\n",
        "      adj[source]=adj[source] | set([target])\n",
        "      if (not directed):\n",
        "        adj[target]=set([source])\n",
        "    else:\n",
        "      adj[source]=adj[source] | set([target])\n",
        "      adj[target]=adj[target] | set([source])\n",
        "    if always_self_loop:\n",
        "      adj[source]=adj[source] | set([source])\n",
        "      adj[target]=adj[target] | set([target])\n",
        "  return adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwwY9uAEk2fa"
      },
      "source": [
        "adj=construct_adjacency_dict(links, directed, always_self_loop=True)\n",
        "assert len(adj.keys())==len(nodes), \"Avem noduri neconectate la nimic\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWx2a-N1miro"
      },
      "source": [
        "print(adj[5])\n",
        "adj_dict=adj\n",
        "print(type(adj[5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZabSVxAbKIoG"
      },
      "source": [
        "## Getting connected components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAqYih49UHQT"
      },
      "source": [
        "def connected_components(neighbors):\n",
        "    seen = set()\n",
        "    def component(node):\n",
        "        nodes = set([node])\n",
        "        while nodes:\n",
        "            node = nodes.pop()\n",
        "            seen.add(node)\n",
        "            nodes |= neighbors[node] - seen\n",
        "            yield node\n",
        "    for node in neighbors:\n",
        "        if node not in seen:\n",
        "            yield component(node)\n",
        "connected_comps=[]\n",
        "for component in connected_components(adj_dict):\n",
        "  connected_comps.append(set(component))\n",
        "print(len(connected_comps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_9EP-jMWo4v"
      },
      "source": [
        "### Component adjacency matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ul-reMOWuOk"
      },
      "source": [
        "# adj_matrices_comps=[]\n",
        "feats_comps=[]\n",
        "classes_comps=[]\n",
        "node_to_index_mappings=[]\n",
        "index_to_node_mappings=[]\n",
        "for comp in connected_comps:\n",
        "  comp=list(comp)\n",
        "  node_to_index_mapping={}\n",
        "  index_to_node_mapping={}\n",
        "  i=0\n",
        "  for node in comp:\n",
        "    node_to_index_mapping[node]=i\n",
        "    index_to_node_mapping[i]=node\n",
        "    i=i+1\n",
        "  node_to_index_mappings.append(node_to_index_mapping)\n",
        "  index_to_node_mappings.append(index_to_node_mapping)\n",
        "  feats_comps.append(feats[comp])\n",
        "  classes_comps.append(torch.tensor([class_map[str(node)] for node in comp]) )\n",
        "  # adj_matrices_comps.append(torch.tensor([ [1 if i in [reordering[neighbor] for neighbor in adj_dict[node]] else 0 for i in range(len(comp))] for node in comp]) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFytbtIIt3c5"
      },
      "source": [
        "# import pickle\n",
        "# with open(basepath+\"adj_matrices_comps\", \"wb\") as file: \n",
        "#   pickle.dump(adj_matrices_comps, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSnNh0vqxBvp"
      },
      "source": [
        "Load component adj matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be5IO3TvuLdT"
      },
      "source": [
        "import pickle\n",
        "with open(basepath+\"adj_matrices_comps\", \"rb\") as file: \n",
        "  loaded_adj_matrices_comps=pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tM0ynTJGX4S"
      },
      "source": [
        "adj_matrices_comps=loaded_adj_matrices_comps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny74kmSfxIBz"
      },
      "source": [
        "# adj_matrices_comps=[matrix.type(torch.FloatTensor) for matrix in loaded_adj_matrices_comps]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHOUyqA7_NsY"
      },
      "source": [
        "# for adj_matrix in adj_matrices_comps:\n",
        "#   adj_matrix[adj_matrix==0]=float('-inf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aPkEhp-NMH0"
      },
      "source": [
        "print(len(adj_matrices_comps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVdN3PwusHa5"
      },
      "source": [
        "print(torch.mean(torch.Tensor([len(component) for component in connected_comps if len(component)>1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRp1Z1q_sf0C"
      },
      "source": [
        "print(torch.sum(torch.tensor([len(component)==1 for component in connected_comps])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cswfHWluq_7n"
      },
      "source": [
        "print(adj_matrices_comps[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceXcCvGAGxW-"
      },
      "source": [
        "### Separate each component into train val test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG-SkYFWG19B"
      },
      "source": [
        "components_train_indexes = []\n",
        "components_val_indexes = []\n",
        "components_test_indexes = []\n",
        "components_classes_train = []\n",
        "components_classes_val = []\n",
        "components_classes_test = []\n",
        "no_train_comps=0\n",
        "no_val_comps=0\n",
        "no_test_comps=0\n",
        "for component_id in range(len(connected_comps)):\n",
        "  component_train_ids=set(connected_comps[component_id]) & set(train_ids)\n",
        "  component_train_indexes=[]\n",
        "  comp_classes_train=[]\n",
        "  if component_train_ids:\n",
        "    no_train_comps+=1\n",
        "    component_train_indexes=[node_to_index_mappings[component_id][node_id] for node_id in component_train_ids]\n",
        "    comp_classes_train=classes_comps[component_id][component_train_indexes]\n",
        "  components_train_indexes.append(component_train_indexes)\n",
        "  components_classes_train.append(comp_classes_train)\n",
        "\n",
        "  component_val_ids=set(connected_comps[component_id]) & set(val_ids)\n",
        "  component_val_indexes=[]\n",
        "  comp_classes_val=[]\n",
        "  if component_val_ids:\n",
        "    no_val_comps+=1\n",
        "    component_val_indexes=[node_to_index_mappings[component_id][node_id] for node_id in component_val_ids]\n",
        "    comp_classes_val=classes_comps[component_id][component_val_indexes]\n",
        "  components_val_indexes.append(component_val_indexes)\n",
        "  components_classes_val.append(comp_classes_val)\n",
        "\n",
        "  component_test_ids=set(connected_comps[component_id]) & set(test_ids)\n",
        "  component_test_indexes=[]\n",
        "  comp_classes_test=[]\n",
        "  if component_test_ids:\n",
        "    no_test_comps+=1\n",
        "    component_test_indexes=[node_to_index_mappings[component_id][node_id] for node_id in component_test_ids]\n",
        "    comp_classes_test=classes_comps[component_id][component_test_indexes]\n",
        "  components_test_indexes.append(component_test_indexes)\n",
        "  components_classes_test.append(comp_classes_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggjGu3w1OsZD"
      },
      "source": [
        "class ComponentsSeparatedData():\n",
        "  def __init__(self, components_train_indexes = [], components_val_indexes = [], components_test_indexes = [],\n",
        "                components_classes_train = [], components_classes_val = [], components_classes_test = [], no_train_comps=0, no_val_comps=0, no_test_comps=0):\n",
        "    self.components_train_indexes=components_train_indexes\n",
        "    self.components_val_indexes=components_val_indexes\n",
        "    self.components_test_indexes=components_test_indexes\n",
        "    self.components_classes_train=components_classes_train\n",
        "    self.components_classes_val=components_classes_val\n",
        "    self.components_classes_test=components_classes_test\n",
        "    self.no_train_comps=no_train_comps\n",
        "    self.no_val_comps=no_val_comps\n",
        "    self.no_test_comps=no_test_comps\n",
        "\n",
        "components_separated_data=ComponentsSeparatedData(components_train_indexes, components_val_indexes, components_test_indexes,\n",
        "                components_classes_train, components_classes_val, components_classes_test, no_train_comps, no_val_comps, no_test_comps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ccAFs4u5Pqa"
      },
      "source": [
        "##Construct (sparse) adjacency matrix (from previously constructed dict)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47QIJQal5UFR"
      },
      "source": [
        "def construct_sparse_adjacency_matrix(adj_dict: dict, indeces=None):\n",
        "  \"\"\"\n",
        "  !!WARNING: about 30-40 minute runtime for ppi dataset\n",
        "  will only construct the indeces and then a vector of ones of length the components of the shape of the indeces vector multiplied\n",
        "  indeces will be a vector of dim 2 x number of neighbors that need to be specified. first line = node index, second line = neighbor index\n",
        "  we need to cat on to the indeces along the second dimension because we keep adding columns\n",
        "  \"\"\"\n",
        "  if indeces == None:\n",
        "    print('We have to construct indeces vector. Brace yourself, it will take a while!')\n",
        "    indeces=torch.LongTensor(2, 1)\n",
        "    for node in adj_dict.keys():\n",
        "      for neighbor in adj_dict[node]:\n",
        "        indeces=torch.cat( (indeces, torch.unsqueeze(torch.LongTensor([node, neighbor]), dim=1) ), dim=1) #unsqueeze along dim 1 will make 1 column and 2 lines\n",
        "    indeces=indeces[:, 1:] #eliminates first column which has arbitrary content and was created in declaration\n",
        "  values=torch.ones(indeces.shape[1])\n",
        "  adj_sparse_matrix=torch.sparse.ShortTensor(indeces, values, torch.Size([len(adj_dict.keys()),len(adj_dict.keys())]))\n",
        "  return adj_sparse_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AV8K-BC2D2n"
      },
      "source": [
        "### Working with indeces as they are"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTpWit1EWPfJ"
      },
      "source": [
        "indeces_loaded=torch.load(basepath+'sparse_adjacency_matrix_indeces.pt')\n",
        "print(indeces_loaded[:, 600:700])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79lKudvI-ox1"
      },
      "source": [
        "adj_matrix=construct_sparse_adjacency_matrix(adj_dict, indeces_loaded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRjPGE2_VJr9"
      },
      "source": [
        "It is very interesting that only *some* nodes appear as neighbors for themselves in initial graph links. I have decided for easier implementation but also because it might be meaningful that only some nodes have links to themselves in initial graph.\n",
        "\n",
        "Ajd matrix has therefore at **least 1** on the main diagonal and **it has 2 in the places where there is a link already in initial graph**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LCg1tcgODBp"
      },
      "source": [
        "#construct adjacency matrix that has all values on diagonal 1\n",
        "adj_matrix=adj_matrix+torch.eye(adj_matrix.shape[0]).to_sparse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4__Asb8d2LvC"
      },
      "source": [
        "### Reprocessing indeces so that they contain all diagonal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFkn44gp-zDt"
      },
      "source": [
        "Perhaps it doesn't make that much sense after all. Let's painfully add 1 to the diagonal where it's missing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-95dHjW-_wH"
      },
      "source": [
        "equal=((indeces_loaded[0]-indeces_loaded[1])==0)\n",
        "\"\"\"\n",
        "now I want to get the elements of the first line for which the result is 1;\n",
        "these will be eliminated from the set of nodes that need to be added to the diagonal\n",
        "\"\"\"\n",
        "already_added_nodes=[indeces_loaded[0,index] for index in range(len(indeces_loaded[0])) if equal[index]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jXMoxtWBrRT"
      },
      "source": [
        "already_added_nodes=set([int(node) for node in already_added_nodes])\n",
        "print(already_added_nodes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm8VEOW1B_c0"
      },
      "source": [
        "print(len(already_added_nodes))\n",
        "print(set(adj_dict.keys()) - already_added_nodes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjczkUdE_nNE"
      },
      "source": [
        "for node in set(adj_dict.keys()) - already_added_nodes:\n",
        "  indeces_loaded=torch.cat( (indeces_loaded, torch.unsqueeze(torch.LongTensor([node, node]), dim=1) ), dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr7hMnRPPNNl"
      },
      "source": [
        "torch.save(indeces_loaded, basepath+'sparse_adjacency_matrix_indeces_diag_eye.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuvAb6lb2Ueu"
      },
      "source": [
        "### Load full diagonal indeces and construct adj matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMmXMZIMPSe4"
      },
      "source": [
        "indeces_loaded=torch.load(basepath+'sparse_adjacency_matrix_indeces_diag_eye.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCOX1P7eOpGd"
      },
      "source": [
        "adj_matrix=construct_sparse_adjacency_matrix(adj_dict, indeces_loaded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH591ALaijb1"
      },
      "source": [
        "## More data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-UCnUcSWb1M"
      },
      "source": [
        "adj_matrix=adj_matrix.type(torch.sparse.FloatTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujyOHtiWQxbn"
      },
      "source": [
        "###Clean the adjacency matrix of its diagonal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeVk8OQnx0AU"
      },
      "source": [
        "Right now adj matrix has diagonal full of ones. If I want diag 0, run this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo1iK8CdQ0Ch"
      },
      "source": [
        "adj_matrix=adj_matrix-torch.eye(adj_matrix.shape[0]).to_sparse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k8znDGqXsyW"
      },
      "source": [
        "### Get the matrix to normalise adjacency matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLooHaDo0PJE"
      },
      "source": [
        "Because both adjacency matrix and the normal matrix will have to be sparse (too big), I'll pass them both to the forward function and take advantage of matrix multiplication associativity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcQzFi3CXwCX"
      },
      "source": [
        "sums_adj_matrix=torch.sparse.sum(adj_matrix, dim=0).to_dense()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4768ZwVTzADX"
      },
      "source": [
        "sums_adj_matrix[sums_adj_matrix==0.]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aADwlzTNX_OE"
      },
      "source": [
        "norm_indeces=torch.cat( (torch.unsqueeze(torch.LongTensor(range(adj_matrix.shape[0])), dim=0),\n",
        "                         torch.unsqueeze(torch.LongTensor(range(adj_matrix.shape[0])), dim=0) ), dim=0)\n",
        "print(norm_indeces.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrDmaACIaUR_"
      },
      "source": [
        "norm_uninversed_matrix=torch.sparse.FloatTensor(norm_indeces, sums_adj_matrix, adj_matrix.shape)\n",
        "norm_matrix=norm_uninversed_matrix**-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IWfrxIrjY06"
      },
      "source": [
        "assert not torch.any(torch.isnan(torch.mm(norm_matrix, feats))), \"Nan values\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU5otOVY1uTu"
      },
      "source": [
        "# 2. A simple multi-perceptron model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ckjtMl1yjk"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crZU_S8e10wy"
      },
      "source": [
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self, in_features, out_classes):\n",
        "    super().__init__()\n",
        "    self.lin1=nn.Linear(in_features=in_features, out_features=1000)\n",
        "    self.lin2=nn.Linear(in_features=1000, out_features=500)\n",
        "    self.lin3=nn.Linear(in_features=500, out_features=125)\n",
        "    self.lin4=nn.Linear(in_features=125, out_features=out_classes)\n",
        "  def forward(self, x):\n",
        "    out=self.lin1(x)\n",
        "    out=F.relu(out)\n",
        "    out=self.lin2(out)\n",
        "    out=F.relu(out)\n",
        "    out=self.lin3(out)\n",
        "    out=F.relu(out)\n",
        "    out=self.lin4(out)\n",
        "    # out=torch.sigmoid(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc3wOhcNQZ8Z"
      },
      "source": [
        "### Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBaUD1Db2ggy"
      },
      "source": [
        "def make_batch_loader_simple_nn(ids_selector: list, id_map: dict, features: np.array, class_map: dict, batch_size: int, shuffle, device):\n",
        "  \"\"\"\n",
        "  id_map: only used for obtaining the right line in features\n",
        "  ids_selector: list of ids that are in the wanted dataset\n",
        "  \"\"\"\n",
        "  out_feats=torch.FloatTensor(features[[id_map[str(idx)] for idx in ids_selector]])\n",
        "  out_classes=torch.FloatTensor([class_map[str(idx)] for idx in ids_selector])\n",
        "  out_feats=out_feats.to(device)\n",
        "  out_classes=out_classes.to(device)\n",
        "  from torch.utils.data import TensorDataset\n",
        "  from torch.utils.data import DataLoader\n",
        "  dataset = TensorDataset(out_feats, out_classes)\n",
        "  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n",
        "  return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS0WEi1o7RNX"
      },
      "source": [
        "train_loader=make_batch_loader_simple_nn(ids_selector=train_ids, id_map=id_map, features=feats, class_map=class_map, batch_size=300, shuffle=True, device=device)\n",
        "val_loader=make_batch_loader_simple_nn(ids_selector=val_ids, id_map=id_map, features=feats, class_map=class_map, batch_size=300, shuffle=True, device=device)\n",
        "test_loader=make_batch_loader_simple_nn(ids_selector=test_ids, id_map=id_map, features=feats, class_map=class_map, batch_size=300, shuffle=True, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP4RcpMfQc23"
      },
      "source": [
        "### Instancing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcCcGJob4t4f"
      },
      "source": [
        "no_features=feats.shape[-1]\n",
        "no_classes=len(class_map['0'])\n",
        "print(no_features, no_classes)\n",
        "print(f'no samples: {feats.shape[0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqVDmU_rrdAU"
      },
      "source": [
        "From http://hagan.okstate.edu/NNDesign.pdf#page=469\n",
        "\n",
        "Nh=Ns/(α∗(Ni+No))\n",
        "\n",
        "Nh = number of hidden neurons.\n",
        "Ni = number of input neurons.\n",
        "No = number of output neurons.\n",
        "Ns = number of samples in training data set.\n",
        "α = an arbitrary scaling factor usually 2-10.\n",
        "\n",
        "Here, Ni+No=50+121=171, Ns=56944"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xua2-31sBxm"
      },
      "source": [
        "nh=56944/(2*(50+121))\n",
        "print(nh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5iUWzcN7-V5"
      },
      "source": [
        "simple_nn=SimpleNN(no_features, no_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZWaojBp9Aew"
      },
      "source": [
        "optim=torch.optim.Adam(simple_nn.parameters(), lr=10e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hahJW9G5AqO"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvwBgc7p4YAb"
      },
      "source": [
        "def train_epoch_simple_nn(model: SimpleNN, optim, train_loader: torch.utils.data.DataLoader, device, epoch, print_every=20):\n",
        "  model=model.to(device)\n",
        "  total_epoch_loss=0.\n",
        "  loss_func=torch.nn.MultiLabelSoftMarginLoss()\n",
        "  num_batches=0\n",
        "  for batch_idx, (batch, batch_labels) in enumerate(train_loader):\n",
        "    optim.zero_grad()\n",
        "    out=model(batch)\n",
        "    loss=loss_func(out, batch_labels)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "      optim.step()\n",
        "      total_epoch_loss+=loss.item()\n",
        "      num_batches+=1\n",
        "      if (batch_idx%print_every == 0):\n",
        "        pass\n",
        "        # print(f'batch {batch_idx} has train loss {loss.item()} on epoch {epoch} \\n\\n')\n",
        "  return total_epoch_loss/num_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vftwi08Ri_I8"
      },
      "source": [
        "train_feats=torch.FloatTensor(feats[[id_map[str(idx)] for idx in train_ids]])\n",
        "train_classes=torch.FloatTensor([class_map[str(idx)] for idx in train_ids])\n",
        "val_feats=torch.FloatTensor(feats[[id_map[str(idx)] for idx in val_ids]])\n",
        "val_classes=torch.FloatTensor([class_map[str(idx)] for idx in val_ids])\n",
        "test_feats=torch.FloatTensor(feats[[id_map[str(idx)] for idx in test_ids]])\n",
        "test_classes=torch.FloatTensor([class_map[str(idx)] for idx in test_ids])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjrcUTYhkGeC"
      },
      "source": [
        "no_epochs=1000\n",
        "save_every=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8whWsxd6sjq"
      },
      "source": [
        "train_every_epoch_loss=[]\n",
        "val_every_epoch_loss=[]\n",
        "test_every_epoch_loss=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV0h4Vo3O_rE"
      },
      "source": [
        "save_identifier='_1000_500_125'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcABasAb6o3b"
      },
      "source": [
        "for e in range(no_epochs):\n",
        "  epoch_train_loss=train_epoch_simple_nn(simple_nn, optim, train_loader, device, e, print_every=200)\n",
        "  with torch.no_grad():\n",
        "    print(f'epoch {e}, train loss: {epoch_train_loss}')\n",
        "    train_loss.append(epoch_train_loss)\n",
        "    # lossfun=torch.nn.BCEWithLogitsLoss()\n",
        "    lossfun=torch.nn.MultiLabelSoftMarginLoss()\n",
        "    epoch_loss=lossfun(simple_nn(val_feats), val_classes)\n",
        "    val_loss.append(epoch_loss.item())\n",
        "    epoch_loss=lossfun(simple_nn(test_feats), test_classes)\n",
        "    test_loss.append(epoch_loss.item())\n",
        "    if (e%save_every==0):\n",
        "      torch.save(simple_nn.state_dict(), basepath+'simple_nn'+save_identifier)\n",
        "      print(f'epoch loss: {epoch_train_loss}')\n",
        "      import pickle\n",
        "      with open(basepath+'simple_nn_train_losses'+save_identifier+'.data', 'wb') as filehandle:\n",
        "        pickle.dump(train_loss, filehandle)\n",
        "      with open(basepath+'simple_nn_val_losses'+save_identifier+'.data', 'wb') as filehandle:\n",
        "        pickle.dump(val_loss, filehandle)\n",
        "      with open(basepath+'simple_nn_test_losses'+save_identifier+'.data', 'wb') as filehandle:\n",
        "        pickle.dump(test_loss, filehandle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtsugC7O45LP"
      },
      "source": [
        "### Loss plot n debugging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9ALQAhF60pW"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt \n",
        "plt.plot(range(1, len(train_every_epoch_loss)+1), train_every_epoch_loss, label='Train loss', color='red')\n",
        "plt.plot(range(1, len(val_every_epoch_loss)+1), val_every_epoch_loss, label='Val loss', color='blue')\n",
        "plt.plot(range(1, len(test_every_epoch_loss)+1), test_every_epoch_loss, label='Test loss', color='green')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtQK8Y4UTNmN"
      },
      "source": [
        "print(train_every_epoch_loss[-100:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3QuqXmjFfw2"
      },
      "source": [
        "with torch.no_grad():\n",
        "  out_train=simple_nn(train_feats)\n",
        "  print(out_train)\n",
        "  loss_train=torch.mean(torch.abs(torch.round(torch.sigmoid(out_train))-train_classes))\n",
        "  print(loss_train)\n",
        "  out_val=simple_nn(val_feats)\n",
        "  loss_val=torch.mean(torch.abs(torch.round(torch.sigmoid(out_val))-val_classes))\n",
        "  print(loss_val)\n",
        "  out_test=simple_nn(test_feats)\n",
        "  loss_test=torch.mean(torch.abs(torch.round(torch.sigmoid(out_test))-test_classes))\n",
        "  print(loss_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpX__bPwy7J2"
      },
      "source": [
        "###**On return**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT680iPOmQOx"
      },
      "source": [
        "simple_nn.load_state_dict(torch.load(basepath+'simple_nn_2000_400'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl4VdfTsyf68"
      },
      "source": [
        "import pickle\n",
        "with open(basepath+'simple_nn_train_losses2.data', 'rb') as filehandle:\n",
        "  train_every_epoch_loss=pickle.load(filehandle)\n",
        "with open(basepath+'simple_nn_val_losses2.data', 'rb') as filehandle:\n",
        "  val_every_epoch_loss=pickle.load(filehandle)\n",
        "with open(basepath+'simple_nn_test_losses2.data', 'rb') as filehandle:\n",
        "  test_every_epoch_loss=pickle.load(filehandle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPOpMwIT4uBP"
      },
      "source": [
        "#3. Simple variant of GCN (mean aggregator) with no adjacency matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWQSAjX94z_w"
      },
      "source": [
        "class GCN(nn.Module):\n",
        "  def __init__(self, neighbors_depth, in_features_size, embedding_size, no_classes, aggregation_func=lambda x: torch.mean(x, dim=0)):\n",
        "    super().__init__()\n",
        "    self.depth=neighbors_depth-1\n",
        "    self.agg=aggregation_func\n",
        "    linears=[]\n",
        "    self.emb_size=embedding_size\n",
        "    for i in range(neighbors_depth):\n",
        "      if i==0:\n",
        "        linears.append(nn.Linear(in_features_size, embedding_size, bias=False))\n",
        "      else:\n",
        "        linears.append(nn.Linear(embedding_size, embedding_size, bias=False))\n",
        "    self.linears=nn.ModuleList(linears)\n",
        "    self.classifier=nn.Linear(embedding_size, no_classes)\n",
        "  def forward(self, x, level):\n",
        "    out=self.linears[level](self.agg(x))\n",
        "    if level==self.depth:\n",
        "      return out\n",
        "    else:\n",
        "      return F.relu(out)\n",
        "  def classify(self, embedded):\n",
        "    # out=F.relu(embedded)\n",
        "    out=self.classifier(embedded)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeqDpH132bFD"
      },
      "source": [
        "## Useless now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhEPzitD9PGz"
      },
      "source": [
        "def get_neighbors(adj_dict, starting_node_id, depth, level=0):\n",
        "  ids=[]\n",
        "  neighbors=list(adj_dict[starting_node_id])\n",
        "  if starting_node_id not in neighbors:\n",
        "    neighbors.append(starting_node_id)\n",
        "  print(f'node {starting_node_id} with neighbors {neighbors}')\n",
        "  if (level<depth-1):\n",
        "    for neighbor in neighbors:\n",
        "      ids.append(get_neighbors(adj_dict, neighbor , depth, level=level+1))\n",
        "  elif (level<depth):\n",
        "    ids=neighbors\n",
        "  return ids\n",
        "a=get_neighbors(adj, 11, 3)\n",
        "print(len(a))\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxeGJ5rcBR3R"
      },
      "source": [
        "def feed(model: GCN, adj_dict: dict, id_map: dict, starting_node_id: int, feats: torch.Tensor, depth: int, level=0):\n",
        "  \"\"\"\n",
        "  CORE FUNCTION:\n",
        "  takes a starting node and the model and produces the embedding, by recursively traversing the node's subgraph up to given depth\n",
        "  for each neighbor of the node it produces the aggregation associated to that neighbor by calling recursively\n",
        "  if last level is reached then produces aggregation of base features of neighbors\n",
        "  \"\"\"\n",
        "  neighbors=list(adj_dict[starting_node_id])\n",
        "  if starting_node_id not in neighbors:\n",
        "    neighbors.append(starting_node_id)\n",
        "  #we got the neighbors\n",
        "  if (level<depth):\n",
        "    feeded, grad=feed(model, adj_dict, id_map, neighbors[0], feats, depth, level=level+1)\n",
        "    print(f'feeded has grad {feeded.grad}; returned grad is {grad}')\n",
        "    level_neighbors_repres=torch.unsqueeze(feeded, dim=0)\n",
        "    for neighbor in neighbors[1:]:\n",
        "      feeded, grad=feed(model, adj_dict, id_map, neighbor, feats, depth, level=level+1)\n",
        "      print(f'feeded has grad {feeded.grad}; returned grad is {grad}')\n",
        "      neighbor_repr=torch.unsqueeze(feeded, dim=0)\n",
        "      level_neighbors_repres=torch.cat((level_neighbors_repres, neighbor_repr), dim=0)\n",
        "    # print(f'node {starting_node_id} at level {level}; has {len(neighbors)} neighbors')\n",
        "    # print(f'representation of {starting_node_id}\\'s neighbors has shape {level_neighbors_repres.shape}')\n",
        "    level_output=model(level_neighbors_repres, level=depth-level)\n",
        "    return level_output, level_output.grad\n",
        "  elif (level==depth): #the case where I have to take the base features\n",
        "    base_features=torch.FloatTensor(feats[[id_map[str(idx)] for idx in neighbors]])\n",
        "    level_output=model(base_features, level=depth-level)\n",
        "    return level_output, level_output.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws1-316y2fEE"
      },
      "source": [
        "## Useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ptlzY6cvcOq"
      },
      "source": [
        "class Node():\n",
        "  def __init__(self, node_id: int, adj_dict: dict, depth=3):\n",
        "    self.idx=node_id\n",
        "    self.depth=depth\n",
        "    self.neighbors_ids=list(adj_dict[self.idx])\n",
        "    if self.idx not in self.neighbors_ids:\n",
        "      self.neighbors_ids.append(self.idx)\n",
        "    self.neighbors_nodes=[]\n",
        "    if depth>0:\n",
        "      self.neighbors_nodes=[Node(neighbor_id, adj_dict, depth=depth-1) for neighbor_id in self.neighbors_ids]\n",
        "  def level_feedforward(self, model, id_map: dict, feats: torch.Tensor, level=0):\n",
        "    if (level==model.depth):\n",
        "      base_features=torch.FloatTensor(feats[[id_map[str(idx)] for idx in self.neighbors_ids]])\n",
        "      level_output=model(base_features, level=model.depth-level)\n",
        "      # print(f'node {self.idx} at level {level} has level output gradient {level_output.grad}')\n",
        "      return level_output\n",
        "    elif (level<model.depth):\n",
        "      \n",
        "      feeded=self.neighbors_nodes[0].level_feedforward(model, id_map, feats, level=level+1)\n",
        "      level_neighbors_repres=torch.unsqueeze(feeded, dim=0)\n",
        "\n",
        "      for neighbor_node in self.neighbors_nodes[1:]:\n",
        "        feeded=neighbor_node.level_feedforward(model, id_map, feats, level=level+1)\n",
        "        neighbor_repr=torch.unsqueeze(feeded, dim=0)\n",
        "        level_neighbors_repres=torch.cat((level_neighbors_repres, neighbor_repr), dim=0)\n",
        "\n",
        "      level_output=model(level_neighbors_repres, level=model.depth-level)\n",
        "      # print(f'node {self.idx} at level {level} has level output gradient {level_output.grad}')\n",
        "      return level_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6Djj4vKERrZ"
      },
      "source": [
        "# for (name, param) in model.named_parameters():\n",
        "#   print(f'param {name} is {param}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LilF-yuJIF49"
      },
      "source": [
        "# def train_epoch_gcn_old(gcn: GCN, optim, adj_dict: dict, id_map: dict, feats: torch.Tensor, train_ids: list, class_map, epoch, print_every=100):\n",
        "#   epoch_loss=0.\n",
        "#   lossfunc=torch.nn.BCEWithLogitsLoss()\n",
        "#   for node_id in train_ids:\n",
        "#     optim.zero_grad()\n",
        "#     node_classes=torch.FloatTensor(class_map[str(node_id)])\n",
        "#     node_embedding=feed(gcn, adj_dict, id_map, node_id, feats, gcn.depth)\n",
        "#     node_predictions=gcn.classify(node_embedding)\n",
        "#     # print(f'model predicts of shape {node_predictions.shape[0]}')\n",
        "#     node_loss=lossfunc(node_predictions, node_classes)\n",
        "#     node_loss.backward()\n",
        "#     with torch.no_grad():\n",
        "#       optim.step()\n",
        "#       epoch_loss+=node_loss\n",
        "#       if node_id%print_every==0:\n",
        "#         print(f'node {node_id} loss is {node_loss} in epoch {epoch}')\n",
        "#         # print(f'node {node_id} embedding is {node_embedding} \\n\\n')\n",
        "#         for (name, param) in model.named_parameters():\n",
        "#             print(f'param {name} is {param}')\n",
        "#   epoch_loss=epoch_loss/len(train_ids)\n",
        "#   print(f'epoch {epoch} has loss {epoch_loss}')\n",
        "\n",
        "#   return (epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqfzIvvCHxK7"
      },
      "source": [
        "def train_epoch_gcn(gcn: GCN, optim, adj_dict: dict, id_map: dict, feats: torch.Tensor, train_ids: list, class_map, epoch, print_every=100):\n",
        "  epoch_loss=0.\n",
        "  lossfunc=torch.nn.BCEWithLogitsLoss()\n",
        "  print_losses=[]\n",
        "  for node_id in train_ids:\n",
        "    optim.zero_grad()\n",
        "    node_classes=torch.FloatTensor(class_map[str(node_id)])\n",
        "    current_node=Node(node_id, adj_dict, depth=model.depth)\n",
        "    node_embedding=current_node.level_feedforward(gcn, id_map, feats, level=0)\n",
        "    node_predictions=gcn.classify(node_embedding)\n",
        "    node_loss=lossfunc(node_predictions, node_classes)\n",
        "    node_loss.backward()\n",
        "    with torch.no_grad():\n",
        "      optim.step()\n",
        "      epoch_loss+=node_loss\n",
        "      if node_id%print_every==0:\n",
        "        # print(f'node {node_id} loss is {node_loss} in epoch {epoch}')\n",
        "        # # print(f'node {node_id} embedding is {node_embedding} \\n\\n')\n",
        "        # for (name, param) in model.named_parameters():\n",
        "        #     print(f'param {name} has grad {param.grad}')\n",
        "        # print(f'computational graph:')\n",
        "        # torchviz.make_dot(node_embedding)\n",
        "        # print(f'loss total loss until now is {epoch_loss/node_id}')\n",
        "        print_losses.append(epoch_loss/node_id)\n",
        "        import matplotlib.pyplot as plt \n",
        "        plt.plot(range(1, len(print_losses)+1), print_losses, label='Train loss', color='red')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "  epoch_loss=epoch_loss/len(train_ids)\n",
        "  print(f'epoch {epoch} has loss {epoch_loss}')\n",
        "\n",
        "  return (epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60O7V4YLGuur"
      },
      "source": [
        "model=GCN(3, feats.shape[-1], 150, no_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q0MZRQ6Ft-V"
      },
      "source": [
        "optim=torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQpoxmuRH_Gj"
      },
      "source": [
        "no_epochs=30\n",
        "train_epoch_losses=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjictAJcGAvn"
      },
      "source": [
        "for e in range(no_epochs):\n",
        "  epoch_loss=train_epoch_gcn(model, optim, adj, id_map, feats, train_ids, class_map, e, print_every=100)\n",
        "  train_epoch_losses.append(epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D-QTz1h2Tex"
      },
      "source": [
        "# 3'. Simple variant of GCN with adjacency matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5amUhw82w7G"
      },
      "source": [
        "Multiply adjacency matrix with all h's to get next h's."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfYxpHtNicdf"
      },
      "source": [
        "## Model definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYFB2CWRi9mb"
      },
      "source": [
        "class GCNFeatureEmbedder(nn.Module):\n",
        "  def __init__(self, in_features, out_features, bias=False):\n",
        "    super().__init__()\n",
        "    self.lin1=nn.Linear(in_features, in_features*2, bias=bias)\n",
        "    self.lin2=nn.Linear(in_features*2, out_features, bias=bias)\n",
        "    # self.lin3=nn.Linear(in_features*2, out_features, bias=bias)\n",
        "  def forward(self, x):\n",
        "    out=self.lin1(x)\n",
        "    out=F.relu(out)\n",
        "    out=self.lin2(out)\n",
        "    # out=F.relu(out)\n",
        "    # out=self.lin3(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iEsOFYUQk_2"
      },
      "source": [
        "class GCN(nn.Module):\n",
        "  def __init__(self, neighbors_depth, in_features_size, embedding_size, no_classes):\n",
        "    super().__init__()\n",
        "    self.depth=neighbors_depth-1\n",
        "    self.emb_size=embedding_size\n",
        "    self.feature_size=in_features_size\n",
        "    linears_for_neighbors=[]\n",
        "    linears_for_self=[]\n",
        "    cur_size=in_features_size*2\n",
        "    for i in range(neighbors_depth-1):\n",
        "        # linears_for_neighbors.append(nn.Linear(cur_size, cur_size*2, bias=False))\n",
        "        # linears_for_self.append(nn.Linear(cur_size, cur_size*2, bias=False))\n",
        "\n",
        "        # linears_for_neighbors.append(GCNFeatureEmbedder(cur_size, cur_size*2))\n",
        "        # linears_for_self.append(GCNFeatureEmbedder(cur_size, cur_size*2))\n",
        "        if i==0:\n",
        "          linears_for_neighbors.append(nn.Linear(in_features_size, cur_size))\n",
        "          linears_for_self.append(nn.Linear(in_features_size, cur_size))\n",
        "        else:\n",
        "          linears_for_neighbors.append(nn.Linear(cur_size, cur_size))\n",
        "          linears_for_self.append(nn.Linear(cur_size, cur_size))\n",
        "\n",
        "        # cur_size=cur_size*2\n",
        "    linears_for_neighbors.append(GCNFeatureEmbedder(cur_size, embedding_size, bias=False))\n",
        "    # linears_for_neighbors.append(nn.Linear(cur_size, embedding_size, bias=False))\n",
        "\n",
        "\n",
        "    linears_for_self.append(GCNFeatureEmbedder(cur_size, embedding_size, bias=False))\n",
        "    # linears_for_self.append(nn.Linear(cur_size, embedding_size, bias=False))\n",
        "\n",
        "\n",
        "    self.linears_for_neighbors=nn.ModuleList(linears_for_neighbors)\n",
        "    self.linears_for_self=nn.ModuleList(linears_for_self)\n",
        "    self.classifier=nn.Linear(embedding_size, no_classes, bias=False)\n",
        "  def forward(self, node_features: torch.Tensor, adj_matrix: torch.sparse.FloatTensor, norm_matrix: torch.sparse.FloatTensor):\n",
        "    \"\"\"\n",
        "    node_features and adjacency matrix have to have the same size i.e. node features must be provided for all nodes\n",
        "    apparently two torch sparse tensors can't be multiplied togehter so I'll have to go for the first multiplication and then the second\n",
        "    norm_matrix is a normalisation diagonal matrix, inverse of the number of the neighbors of each node on the diagonal\n",
        "    \"\"\"\n",
        "    current_feats=node_features\n",
        "    for i in range(len(self.linears_for_neighbors)) :\n",
        "      linear_neighbors = self.linears_for_neighbors[i]\n",
        "      linear_self = self.linears_for_self[i]\n",
        "      current_feats=linear_neighbors( torch.mm(norm_matrix, torch.mm(adj_matrix, current_feats)) ) + linear_self(torch.mm(norm_matrix,current_feats))\n",
        "      current_feats=F.relu(current_feats)\n",
        "    return current_feats\n",
        "  def classify(self, embedded):\n",
        "    #no activation here because it already went through activation at previous level and it will go through sigmo once outputed\n",
        "    out=self.classifier(embedded)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5GITZffYoxq"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQdeQgHf1c9w"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqsj2xbQaid5"
      },
      "source": [
        "def get_preds_n_classes(ids_selector, all_preds, class_map: dict):\n",
        "  out_preds=all_preds[[idx for idx in ids_selector]].to(device)\n",
        "  out_classes=torch.FloatTensor([class_map[str(idx)] for idx in ids_selector]).to(device)\n",
        "  return out_preds, out_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmnFvX59YROs"
      },
      "source": [
        "def train_epoch_adjacency_gcn(model, optim, adj_matrix, norm_matrix, feats, train_ids, class_map, device):\n",
        "  model=model.to(device)\n",
        "  \n",
        "  loss_func=torch.nn.BCEWithLogitsLoss()\n",
        "  optim.zero_grad()\n",
        "  preds=model.classify(model(feats, adj_matrix, norm_matrix))\n",
        "  train_preds, train_classes=get_preds_n_classes(train_ids, preds, class_map)\n",
        "  loss=loss_func(train_preds, train_classes)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    optim.step()\n",
        "    return loss.item(), preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ0UNb2FuYtu"
      },
      "source": [
        "def get_accuracy(predictions, labels, probability=0.5):\n",
        "  \"\"\"\n",
        "  predictions are of the shape no_nodes x no_classes, representing probability of each node being in each class\n",
        "  labels are the same shape only binary\n",
        "\n",
        "  average='weighted' is used in f1_score because it accounts for possible class imbalances\n",
        "  \"\"\"\n",
        "  assert predictions.shape == labels.shape, \"Predictions and labels don't have same shape: \"+{predictions.shape}+\" vs. \"+{labels.shape}+\" respectively.\"\n",
        "  from sklearn.metrics import f1_score\n",
        "  cutoff=(predictions>probability).type(torch.FloatTensor)\n",
        "  score=f1_score(y_true=labels, y_pred=cutoff, average='weighted')\n",
        "  return(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayEBN_g_1gOu"
      },
      "source": [
        "### Actual training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoU6W8k3cpRC"
      },
      "source": [
        "no_epochs=10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMNguArjzoxF"
      },
      "source": [
        "model=GCN(3, feats.shape[-1], 150, no_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9B6qdLyFnMr"
      },
      "source": [
        "save_identifier=str(model.emb_size)+'_twiceinfeats_hybrid_3iters_withselfs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFcJJRRFcy07"
      },
      "source": [
        "optim=torch.optim.Adam(model.parameters(), lr=10e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlWiJ-CvdAU8"
      },
      "source": [
        "train_every_epoch_loss=[]\n",
        "val_every_epoch_loss=[]\n",
        "test_every_epoch_loss=[]\n",
        "train_every_epoch_score=[]\n",
        "val_every_epoch_score=[]\n",
        "test_every_epoch_score=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrGHRRRJcr84"
      },
      "source": [
        "def train_gcn_model(model, optim, no_epochs, save_identifier, model_type, save_every):\n",
        "  for e in range(no_epochs):\n",
        "    # print(f'epoch {e}')\n",
        "    train_epoch_loss, preds = train_epoch_adjacency_gcn(model, optim, adj_matrix, norm_matrix, feats, train_ids, class_map, device)\n",
        "    loss_func=torch.nn.BCEWithLogitsLoss()\n",
        "    with torch.no_grad():\n",
        "      val_preds, val_classes=get_preds_n_classes(val_ids, preds, class_map)\n",
        "      test_preds, test_classes=get_preds_n_classes(test_ids, preds, class_map)\n",
        "      train_preds, train_classes=get_preds_n_classes(train_ids, preds, class_map)\n",
        "\n",
        "      val_epoch_loss=loss_func(val_preds, val_classes)\n",
        "      test_epoch_loss=loss_func(test_preds, test_classes)\n",
        "      #we already have the train loss so no need to calculate it\n",
        "\n",
        "      #we pass through simgoid because network doesn't when classifying so that we can use BCEWithLogitsLoss, which expects logits, not probabilities, for numeric stability\n",
        "      train_epoch_score=get_accuracy(torch.sigmoid(train_preds), train_classes)\n",
        "      val_epoch_score=get_accuracy(torch.sigmoid(val_preds), val_classes)\n",
        "      test_epoch_score=get_accuracy(torch.sigmoid(test_preds), test_classes)\n",
        "\n",
        "      print(f'train epoch {e} loss {train_epoch_loss} and score {train_epoch_score} \\n\\n\\n')\n",
        "\n",
        "      #adding to total vectors for plot\n",
        "      train_every_epoch_loss.append(train_epoch_loss)\n",
        "      val_every_epoch_loss.append(val_epoch_loss)\n",
        "      test_every_epoch_loss.append(test_epoch_loss)\n",
        "      train_every_epoch_score.append(train_epoch_score)\n",
        "      val_every_epoch_score.append(val_epoch_score)\n",
        "      test_every_epoch_score.append(test_epoch_score)\n",
        "      if e%save_every==0:\n",
        "        torch.save(model.state_dict(), basepath+model_type+'_adjacency_emb'+save_identifier)\n",
        "        import pickle\n",
        "        with open(basepath+model_type+'_train_losses_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(train_every_epoch_loss, filehandle)\n",
        "        with open(basepath+model_type+'_adj_val_losses_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(val_every_epoch_loss, filehandle)\n",
        "        with open(basepath+model_type+'_adj_test_losses_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(test_every_epoch_loss, filehandle)\n",
        "        with open(basepath+model_type+'_adj_train_scores_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(train_every_epoch_score, filehandle)\n",
        "        with open(basepath+model_type+'_adj_val_scores_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(val_every_epoch_score, filehandle)\n",
        "        with open(basepath+model_type+'_adj_test_scores_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(test_every_epoch_score, filehandle)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNuDszLD6w-b"
      },
      "source": [
        "train_gcn_model(model, optim, no_epochs, save_identifier, 'gcn_adj', save_every=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBUzCnCtjAM6"
      },
      "source": [
        "#not really used anymore since saving is done in training loop\n",
        "torch.save(model.state_dict(), basepath+'gcn_adjacency_emb'+save_identifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEBattUjoPEd"
      },
      "source": [
        "## Loading back and plotting "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAa5BhKDGRFT"
      },
      "source": [
        "Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpOonAPeR7o1"
      },
      "source": [
        "model.load_state_dict(torch.load(basepath+'gcn_adjacency_emb'+load_identifier))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H15RjgHjGQBv"
      },
      "source": [
        "!ls '$basepath'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wphNxAKmPfkk"
      },
      "source": [
        "def load_losses_n_scores(basepath, model_identifier, load_identifier, import_scores=False):\n",
        "  #for some arhitectures scores weren't computed\n",
        "  import pickle\n",
        "  with open(basepath+model_identifier+'train_losses'+load_identifier+'.data', 'rb') as filehandle:\n",
        "    train_loss=pickle.load(filehandle)\n",
        "  with open(basepath+model_identifier+'val_losses'+load_identifier+'.data', 'rb') as filehandle:\n",
        "    val_loss=pickle.load(filehandle)\n",
        "  with open(basepath+model_identifier+'test_losses'+load_identifier+'.data', 'rb') as filehandle:\n",
        "    test_loss=pickle.load(filehandle)\n",
        "  \n",
        "  if import_scores:\n",
        "    with open(basepath+model_identifier+'train_scores'+load_identifier+'.data', 'rb') as filehandle:\n",
        "      train_score=pickle.load(filehandle)\n",
        "    with open(basepath+model_identifier+'val_scores'+load_identifier+'.data', 'rb') as filehandle:\n",
        "      val_score=pickle.load(filehandle)\n",
        "    with open(basepath+model_identifier+'test_scores'+load_identifier+'.data', 'rb') as filehandle:\n",
        "      test_score=pickle.load(filehandle)\n",
        "    return (train_loss, val_loss, test_loss, train_score, val_score, test_score)\n",
        "  else:\n",
        "    return (train_loss, val_loss, test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S4qEN7YHJmV"
      },
      "source": [
        "def plot_losses_n_scores(train_loss, val_loss, test_loss, graph_title, begin_plot_index=1000,\n",
        "         train_score=None, val_score=None, test_score=None):\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.figure() #create new plot\n",
        "  plt.plot(range(begin_plot_index+1, len(train_loss)+1), train_loss[begin_plot_index:], label='Train loss', color='red')\n",
        "  plt.plot(range(begin_plot_index+1, len(val_loss)+1), val_loss[begin_plot_index:], label='Val loss', color='blue')\n",
        "  plt.plot(range(begin_plot_index+1, len(test_loss)+1), test_loss[begin_plot_index:], label='Test loss', color='green')\n",
        "  if(train_score != None):\n",
        "    plt.plot(range(begin_plot_index+1, len(train_score)+1), train_score[begin_plot_index:], label='Train score', color='yellow')\n",
        "  if(val_score != None):\n",
        "    plt.plot(range(begin_plot_index+1, len(val_score)+1), val_score[begin_plot_index:], label='Val score', color='purple')\n",
        "  if(test_score != None):\n",
        "    plt.plot(range(begin_plot_index+1, len(test_score)+1), test_score[begin_plot_index:], label='Test score', color='cyan')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend()\n",
        "  plt.title(graph_title)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxr6SZCYJFrY"
      },
      "source": [
        "def get_n_plot_losses_n_scores(basepath, model_identifier,load_identifier, begin_plot_index=500, scores=False):\n",
        "  if scores:\n",
        "    trl, vl, tel, trs, vs, tes=load_losses_n_scores(basepath, model_identifier, load_identifier, scores)\n",
        "  else:\n",
        "    trl, vl, tel = load_losses_n_scores(basepath, model_identifier, load_identifier, scores)\n",
        "    trs, vs, tes = None, None, None\n",
        "  plot_losses_n_scores(tr, v, te, model_identifier+load_identifier, begin_plot_index, trs, vs, tes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9fu8fN6ILEh"
      },
      "source": [
        "load_identifier='_'+str(model.emb_size)+'_ladder_embedders_3_selfs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCASftofIZGt"
      },
      "source": [
        "load_identifier=save_identifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aULWUqSz3Qoc"
      },
      "source": [
        "#if losses and scores are already in memory\n",
        "plot_losses_n_scores(train_every_epoch_loss, val_every_epoch_loss, test_every_epoch_loss, 'Memory is a weird thing', 20,\n",
        "         train_every_epoch_score, val_every_epoch_score, test_every_epoch_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTT12gTgyuyD"
      },
      "source": [
        "get_n_plot_losses(basepath, 'gcn_adj_', load_identifier, begin_plot_index=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBqBIT7FIZ2F"
      },
      "source": [
        "load_ids=['_100_ladder_embedders_3_selfs', '_150_4_hybrid', '_200_ladder_embedders_3_selfs', '_250_3_hybrid']\n",
        "for load_id in load_ids:\n",
        "  get_n_plot_losses(basepath, 'gcn_adj_', load_id, 10)\n",
        "load_ids=['_1000_500_125']\n",
        "for load_id in load_ids:\n",
        "  get_n_plot_losses(basepath, 'simple_nn_', load_id, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4fN3NXneyJ3"
      },
      "source": [
        "## Dummy example to test on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAtKtU6veaUU"
      },
      "source": [
        "#dummy example\n",
        "dum_feats=torch.FloatTensor([[1, 1, 0, 1], [1, 0, 1, 0], [0, 0, 0, 1], [1, 1, 1, 1], [0, 0, 1, 0], [1, 0, 1, 0]])\n",
        "dum_classes=torch.FloatTensor([[1, 0], [1, 1], [1, 0], [0,0], [1, 1], [0, 1]])\n",
        "dum_adj_matrix=torch.FloatTensor([[1, 0, 1, 1, 0, 0], [0, 1, 0, 0, 0, 1],\n",
        "                                  [1, 1, 1, 0, 0, 0], [0, 1, 0, 1, 0, 1],\n",
        "                                  [0, 0, 0, 1, 1, 0], [0, 0, 1, 0, 1, 1]\n",
        "                                  ])\n",
        "dum_sums_adj_matrix=torch.sum(dum_adj_matrix, dim=0)\n",
        "dum_sums_adj_matrix[dum_sums_adj_matrix==0.]=1\n",
        "dum_norm_matrix=torch.diag(dum_sums_adj_matrix**-1)\n",
        "print(dum_norm_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTtwQtnKK59U"
      },
      "source": [
        "dum_model=GCN(3, dum_feats.shape[-1], 100, dum_classes.shape[-1])\n",
        "dum_optim=torch.optim.Adam(dum_model.parameters(), lr=10e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAiOYsGqLeqb"
      },
      "source": [
        "for e in range(1000):\n",
        "  loss_func=torch.nn.BCEWithLogitsLoss()\n",
        "  dum_optim.zero_grad()\n",
        "  dum_embeddings=dum_model(dum_feats, dum_adj_matrix, dum_norm_matrix)\n",
        "  dum_preds=dum_model.classify(dum_embeddings)\n",
        "  dum_loss=loss_func(dum_preds, dum_classes)\n",
        "  dum_loss.backward()\n",
        "  with torch.no_grad():\n",
        "    dum_optim.step()\n",
        "    print(f'epoch {e}')\n",
        "    print()\n",
        "    # print(dum_embeddings)\n",
        "    print(dum_preds)\n",
        "    print(dum_classes)\n",
        "    print(dum_loss.item())\n",
        "    print('\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DIKREif9XNT"
      },
      "source": [
        "# 4. Graph Attention Network (GAT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-HluX8n9ojK"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_rsFWUe1BMN"
      },
      "source": [
        "### Old forward method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdcHkOk-WZ7H"
      },
      "source": [
        "# # newest old forward\n",
        "#   def forward(self, node_features: torch.Tensor, index_mapping: dict, adj_dict: dict, focus_ids: list):\n",
        "#     \"\"\"\n",
        "#     -node_features is a tensor of features of nodes required for all iterrations in batch\n",
        "#     -index_mapping maps actual node_ids to indexes of node_features rows (which are the ones which appear in adj dict)\n",
        "#     -adj_dict is an adjacency dictionary of all the nodes (no point in constructing one just with the nodes needed for iteration)\n",
        "#     -focus_ids is a list of lists of all the ids that are important at a given level (from left to right: farthest to nearest)\n",
        "#     focus_ids[0] will be the ids of nodes that are at level 1, i.e. immediately above leaves etc.\n",
        "#      The index mapping will need to be updated at each iteration so that we have a clue what's going on\n",
        "#     \"\"\"\n",
        "\n",
        "#     #START THE ITERATIONS\n",
        "#     current_feats=node_features\n",
        "#     for i in range(len(self.linears_for_neighbors)) :\n",
        "#       #an iteration starts\n",
        "#       print(f'iteration {i}')\n",
        "#       linear_neighbors = self.linears_for_neighbors[i]\n",
        "#       attention=self.attentions[i]\n",
        "      \n",
        "#       next_feats=torch.FloatTensor(len(focus_ids[i]), linear_neighbors.out_features)\n",
        "#       new_index_mapping={}\n",
        "#       current_row=0\n",
        "#       for node in focus_ids[i]:\n",
        "#         node_neighbors_feats=current_feats[[index_mapping[neighbor] for neighbor in adj_dict[node]]] #will have shape no_neighbors x no_feats_per_node\n",
        "#         node_feats=current_feats[[index_mapping[node]]]\n",
        "#         # print(f'node {node} neighbor feats shape {node_neighbors_feats.shape} and self feats shape {node_feats.shape}')\n",
        "#         node_attention_feeder=torch.cat( (linear_neighbors(node_neighbors_feats.view(node_neighbors_feats.shape[0], -1)),\n",
        "#                                           linear_neighbors(node_feats.view(1,-1).repeat(node_neighbors_feats.shape[0], 1)) ), dim=1)\n",
        "#         #get attention coefficients and normalise them\n",
        "#         node_attention_coefficients=F.leaky_relu(attention(node_attention_feeder), negative_slope=0.2)\n",
        "#         node_attention_coefficients=F.softmax(node_attention_coefficients, dim=0)\n",
        "#         # print(f'after node {node} current attention feeder has shape {current_attention_feeder.shape}')\n",
        "        \n",
        "#         #get linouts\n",
        "#         node_neighbor_linout_feats=linear_neighbors(node_neighbors_feats)\n",
        "#         #compute next feats\n",
        "#         next_feats[current_row]=torch.mm(node_attention_coefficients.view(1, len(list(adj_dict[node]))),\n",
        "#                                     node_neighbor_linout_feats.view(len(list(adj_dict[node])),-1))\n",
        "#         #sorting the index messiness\n",
        "#         new_index_mapping[node]=current_row\n",
        "#         current_row += 1\n",
        "#       current_feats=next_feats\n",
        "#       index_mapping=new_index_mapping\n",
        "#       print(f'final feats out of layer {i} have shape {current_feats.shape}')\n",
        "#       current_feats=F.relu(current_feats)\n",
        "#     return current_feats, index_mapping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S3F6h_46q9_"
      },
      "source": [
        "# #backup \"global\" epoch forward\n",
        "# #START THE ITERATIONS\n",
        "#     current_feats=node_features\n",
        "#     for i in range(len(self.linears_for_neighbors)) :\n",
        "#       #an iteration starts\n",
        "#       linear_neighbors = self.linears_for_neighbors[i]\n",
        "#       attention=self.attentions[i]\n",
        "      \n",
        "#       next_feats=torch.FloatTensor(current_feats.shape[0], linear_neighbors.out_features)\n",
        "#       for node in range(len(adj_dict.keys())):\n",
        "#         node_neighbors_feats=current_feats[list(adj_dict[node])] #will have shape no_neighbors x no_feats_per_node\n",
        "#         node_feats=current_feats[int(node)]\n",
        "#         node_attention_feeder=torch.cat( (linear_neighbors(node_neighbors_feats.view(node_neighbors_feats.shape[0], -1)),\n",
        "#                                           linear_neighbors(node_feats.view(1,node_feats.shape[0]).repeat(node_neighbors_feats.shape[0], 1)) ), dim=1)\n",
        "#         #variant WITHOUT W\n",
        "#         # node_attention_feeder=torch.cat( (node_neighbors_feats.view(node_neighbors_feats.shape[0], -1),\n",
        "#         #                                       node_feats.view(1,node_feats.shape[0]).repeat(node_neighbors_feats.shape[0], 1) ), dim=1)\n",
        "#         #node attention feeder will have shape no_neighbors_of_node x no_node_features*2\n",
        "\n",
        "#         #get attention coefficients and normalise them\n",
        "#         node_attention_coefficients=F.leaky_relu(attention(node_attention_feeder), negative_slope=0.2)\n",
        "#         node_attention_coefficients=F.softmax(node_attention_coefficients, dim=0)\n",
        "#         # print(f'after node {node} current attention feeder has shape {current_attention_feeder.shape}')\n",
        "        \n",
        "#         #get linouts\n",
        "#         node_neighbor_linout_feats=linear_neighbors(current_feats[list(adj_dict[node])])\n",
        "#         #compute next feats\n",
        "#         next_feats[node]=torch.mm(node_attention_coefficients.view(1, len(list(adj_dict[node]))),\n",
        "#                                     node_neighbor_linout_feats.view(len(list(adj_dict[node])),-1))\n",
        "        \n",
        "#       current_feats=next_feats\n",
        "#       print(f'final feats out of layer {i} have shape {current_feats.shape}')\n",
        "#       current_feats=F.relu(current_feats)\n",
        "#     return current_feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHUBryfa09jY"
      },
      "source": [
        "# def forward_old(self, node_features: torch.Tensor, adj_dict: dict):\n",
        "#     #GETTING NODE NEIGHBORS INDECES ONCE AND FOR ALL\n",
        "#     node_neighbors_indeces=[] #a list indicating up to where in the output attention feeder matrix one should look to find the features of the node neighbors\n",
        "#     for node in range(len(adj_dict.keys())):\n",
        "#       if node_neighbors_indeces:\n",
        "#         node_neighbors_indeces.append(node_neighbors_indeces[-1]+len(adj_dict[node]))\n",
        "#       else:\n",
        "#         node_neighbors_indeces.append(len(adj_dict[node]))\n",
        "  \n",
        "#     #START THE ITERATIONS\n",
        "#     current_feats=node_features\n",
        "#     for i in range(len(self.linears_for_neighbors)) :\n",
        "#       #an iteration starts\n",
        "#       linear_neighbors = self.linears_for_neighbors[i]\n",
        "#       attention=self.attentions[i]\n",
        "\n",
        "\n",
        "\n",
        "#       #constructing the attention coefficients\n",
        "#       node_neighbors_feats=current_feats[list(adj_dict[0])] #will have shape no_neighbors x no_feats_per_node\n",
        "#       node_feats=current_feats[int(0)]\n",
        "#       # current_attention_feeder=torch.cat( (linear_neighbors(node_neighbors_feats.view(node_neighbors_feats.shape[0], -1)),\n",
        "#       #                                           linear_neighbors(node_feats.view(1,node_feats.shape[0]).repeat(node_neighbors_feats.shape[0], 1))), dim=1)\n",
        "#       #variant WITHOUT W:\n",
        "#       current_attention_feeder=torch.cat( (node_neighbors_feats.view(node_neighbors_feats.shape[0], -1),\n",
        "#                                                 node_feats.view(1,node_feats.shape[0]).repeat(node_neighbors_feats.shape[0], 1) ), dim=1)\n",
        "#       for node in range(1,len(adj_dict.keys())):\n",
        "#         node_neighbors_feats=current_feats[list(adj_dict[node])] #will have shape no_neighbors x no_feats_per_node\n",
        "#         node_feats=current_feats[int(node)]\n",
        "#         # current_attention_feeder=torch.cat( (current_attention_feeder,\n",
        "#         #                                       torch.cat( (linear_neighbors(node_neighbors_feats.view(node_neighbors_feats.shape[0], -1)),\n",
        "#         #                                       linear_neighbors(node_feats.view(1,node_feats.shape[0]).repeat(node_neighbors_feats.shape[0], 1)) ), dim=1) )\n",
        "#         # , dim=0)\n",
        "#         #variant WITHOUT W\n",
        "#         current_attention_feeder=torch.cat( (current_attention_feeder,\n",
        "#                                               torch.cat( (node_neighbors_feats.view(node_neighbors_feats.shape[0], -1),\n",
        "#                                               node_feats.view(1,node_feats.shape[0]).repeat(node_neighbors_feats.shape[0], 1) ), dim=1) )\n",
        "#         , dim=0)\n",
        "#         # print(f'after node {node} current attention feeder has shape {current_attention_feeder.shape}')\n",
        "#       #current attention feeder will have shape no_links_in_graph x no_node_features*2\n",
        "#       attention_coefficients=F.leaky_relu(attention(current_attention_feeder), negative_slope=0.2) #negative slope of 0.2 was used in the article\n",
        "#       #attention_coefficients will have shape no_links_in_graph x 1 (1 coef for each link)\n",
        "\n",
        "\n",
        "#       #CONSTRUCTING NEXT FEATURES\n",
        "#       next_feats=torch.FloatTensor(current_feats.shape[0], linear_neighbors.out_features)\n",
        "#       #using attention coefficients to compute next level features\n",
        "#         #WE NEED TO RECOMPUTE THE RESULTS OF PASSING THROUGH THE LINEARS BECAUSE THEY WERE ALREADY USED IN PASSING THROUGH ATTENTION\n",
        "#       node_neighbor_linout_feats=linear_neighbors(current_feats[list(adj_dict[0])])\n",
        "#       #normalising first node attentions\n",
        "#       attention_coefficients[:node_neighbors_indeces[0]]=F.softmax(attention_coefficients[:node_neighbors_indeces[0]], dim=0)\n",
        "#       next_feats[0]=torch.mm(attention_coefficients[:node_neighbors_indeces[0]].view(1, node_neighbors_indeces[0]),\n",
        "#                             node_neighbor_linout_feats.view(node_neighbors_indeces[0], -1))\n",
        "#       for node in range(1,len(adj_dict.keys())):\n",
        "#         #I want dot product between attentions of current node and the outputs of current node neighbors through through linear\n",
        "#         #To use mathmul, attentions need to be shape 1 x no_neighbors_current_node\n",
        "#         #                outputs through linears need to be shape no_neighbors_current_node x output_features_of_linear_layer\n",
        "\n",
        "#         #normalising:\n",
        "#         attention_coefficients[node_neighbors_indeces[node-1]:node_neighbors_indeces[node]]=F.softmax(attention_coefficients[node_neighbors_indeces[node-1]:node_neighbors_indeces[node]], dim=0)\n",
        "\n",
        "#         #getting output feats again:\n",
        "#         node_neighbor_linout_feats=linear_neighbors(current_feats[list(adj_dict[node])])\n",
        "\n",
        "#         #computation:\n",
        "#         next_feats[node]=torch.mm(attention_coefficients[node_neighbors_indeces[node-1]:node_neighbors_indeces[node]].view(1, node_neighbors_indeces[node]-node_neighbors_indeces[node-1]),\n",
        "#                                     node_neighbor_linout_feats.view(node_neighbors_indeces[node]-node_neighbors_indeces[node-1],-1))\n",
        "#       current_feats=next_feats\n",
        "#       return attention_coefficients\n",
        "#       print(f'final feats out of layer {i} have shape {current_feats.shape}')\n",
        "#       current_feats=F.relu(current_feats)\n",
        "#     return current_feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz-kU9tL3qLg"
      },
      "source": [
        "Batches will consist of the features of all the nodes needed **for all iterations**, but features will be augmented with a dimension that tells the actual node they correspond to (when making a batch-feature tensor, the node certain features pertain to will no longer be the row number of those features). The model receives an adjacency dict **only of the nodes needed for all iterations** and the features corresponding to that iteration. The batch adjacency dict will be constructed in the train_epoch function, while the batch features will be constructed in a separate function which will (hopefully) act as a loader. I'll also have a torch loader just for ids so I can get batches in a random way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9_vY5qj1EXG"
      },
      "source": [
        "### Class def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LpuOwvXMHpH"
      },
      "source": [
        "class GAT(nn.Module):\n",
        "  def __init__(self, no_iters, in_features_size, embedding_size, no_classes):\n",
        "    \"\"\"\n",
        "    2 attentions for each iteration, one for neighbors, the other for nodes; then summed in forward\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.no_iters=no_iters\n",
        "    self.emb_size=embedding_size\n",
        "    self.feature_size=in_features_size\n",
        "    linears_for_neighbors=[]\n",
        "    linears_for_self=[]\n",
        "    attentions1=[]\n",
        "    attentions2=[]\n",
        "    cur_size=in_features_size*2\n",
        "    for i in range(no_iters-1):\n",
        "        if i==0:\n",
        "          linears_for_neighbors.append(nn.Linear(in_features_size, cur_size, bias=False))\n",
        "          # linears_for_self.append(nn.Linear(in_features_size, cur_size, bias=False))\n",
        "          attentions1.append(nn.Linear(cur_size, 1, bias=False))\n",
        "          attentions2.append(nn.Linear(cur_size, 1, bias=False))\n",
        "          # attentions.append(nn.Linear(in_features_size*2, 1)) #variant WITHOUT W\n",
        "        else:\n",
        "          linears_for_neighbors.append(nn.Linear(cur_size, cur_size, bias=False))\n",
        "          # linears_for_self.append(nn.Linear(cur_size, cur_size, bias=False))\n",
        "          #attentions has to have 2*OUTPUT size of linears_for_neighbors\n",
        "          attentions1.append(nn.Linear(cur_size, 1, bias=False))\n",
        "          attentions2.append(nn.Linear(cur_size, 1, bias=False))\n",
        "        # cur_size=cur_size*2\n",
        "    # linears_for_neighbors.append(GCNFeatureEmbedder(cur_size, embedding_size, bias=False))\n",
        "    linears_for_neighbors.append(nn.Linear(cur_size, embedding_size, bias=False))\n",
        "    # linears_for_self.append(nn.Linear(cur_size, embedding_size, bias=False))\n",
        "    attentions1.append(nn.Linear(embedding_size, 1, bias=False))\n",
        "    attentions2.append(nn.Linear(embedding_size, 1, bias=False))\n",
        "    # attentions.append(nn.Linear(cur_size*2,1)) #variant WITHOUT W\n",
        "    self.linears_for_neighbors=nn.ModuleList(linears_for_neighbors)\n",
        "    self.attentions1=nn.ModuleList(attentions1)\n",
        "    self.attentions2=nn.ModuleList(attentions2)\n",
        "    self.classifier=nn.Linear(embedding_size, no_classes, bias=False)\n",
        "  \n",
        "  def forward(self, feats: torch.Tensor, adj_matrix: torch.Tensor):\n",
        "    \"\"\"\n",
        "    -feats are all the features of all nodes in a connected component\n",
        "    -adj_matrix is the adjacency matrix of that component (has dimension no_nodes_in_component^2)\n",
        "    \"\"\"\n",
        "    #START THE ITERATIONS\n",
        "    current_feats=feats\n",
        "    for i in range(len(self.linears_for_neighbors)) :\n",
        "      #an iteration starts\n",
        "      proj_neighbors=self.attentions1[i](self.linears_for_neighbors[i](current_feats))\n",
        "      proj_nodes=self.attentions2[i](self.linears_for_neighbors[i](current_feats))\n",
        "      #proj_neighbors and _nodes will both be of size no_nodes_in_batch x 1\n",
        "      attention_coefs=torch.add(proj_neighbors.view(1, -1), proj_nodes.view(-1, 1))\n",
        "\n",
        "      #now element attention_coefs[i, j] is attention of node j seen as (potential) neighbor of node i\n",
        "      #lin i of attention_coefs will be coefs associate with node i (coefs of neighbors)\n",
        "\n",
        "      #masking again: (element wise matrix multiplication with adjacency matrix, which is masked with -inf where there are no links for softmax - OUTSIDE FWD)\n",
        "      \n",
        "      # attention_coefs=torch.mul(adj_matrix, attention_coefs)\n",
        "      # nans=torch.isnan(attention_coefs)\n",
        "      # infs=torch.isinf(attention_coefs)\n",
        "      # if torch.any(nans):\n",
        "      #   attention_coefs[nans]=float('-inf') #the 0's in the attention_coefs matrix that were multiplied by -inf\n",
        "      # if torch.any(infs):\n",
        "      #   attention_coefs[infs]=float('-inf') #the negative numbers in the coefs matrix that were multiplied by -inf => +inf\n",
        "      \n",
        "      attention_coefs[adj_matrix==0]=float('-inf')\n",
        "      \n",
        "      #passing through leakyReLU\n",
        "      leaky=torch.nn.LeakyReLU(0.2)\n",
        "      attention_coefs=leaky(attention_coefs)\n",
        "\n",
        "\n",
        "      attention_coefs=torch.softmax(attention_coefs, dim=1) #dim=1 i.e. softmax along each ROW\n",
        "\n",
        "      current_feats=torch.mm(attention_coefs, self.linears_for_neighbors[i](current_feats))\n",
        "      # if (current_feats.shape[0]==1): print(f'iteration {i} feats: {current_feats}')\n",
        "    return current_feats\n",
        "  def classify(self, embedded):\n",
        "    #no activation here because it already went through activation at previous level and it will go through sigmo once outputed\n",
        "    out=self.classifier(embedded)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33nl40Z-5RWC"
      },
      "source": [
        "## Dummy example to test on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcbG8wYG5RWH"
      },
      "source": [
        "#dummy example\n",
        "dum_feats=torch.FloatTensor([[1, 1, 0, 1], [1, 0, 1, 0], [0, 0, 0, 1], [1, 1, 1, 1], [0, 0, 1, 0], [1, 0, 1, 0]])\n",
        "dum_classes=torch.FloatTensor([[1, 0], [1, 1], [1, 0], [0,0], [1, 1], [0, 1]])\n",
        "dum_adj_matrix=torch.FloatTensor([[1, 0, 1, 1, 0, 0], [0, 1, 0, 0, 0, 1],\n",
        "                                  [1, 1, 1, 0, 0, 0], [0, 1, 0, 1, 0, 1],\n",
        "                                  [0, 0, 0, 1, 1, 0], [0, 0, 1, 0, 1, 1]\n",
        "                                  ])\n",
        "dum_adj_dict={0: [0, 2, 3], 1: [1, 5], 2:[0, 1, 2], 3:[1, 3, 5], 4:[3,4], 5:[2,4,5]}\n",
        "print(dum_adj_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFZPX3Ru5RWR"
      },
      "source": [
        "dum_model=GAT(2, dum_feats.shape[-1], 100, dum_classes.shape[-1])\n",
        "dum_optim=torch.optim.Adam(dum_model.parameters(), lr=10e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waevcgky6b8J"
      },
      "source": [
        "a=dum_model(dum_feats,dum_adj_matrix)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4dIMsA45RWY"
      },
      "source": [
        "for e in range(1):\n",
        "  loss_func=torch.nn.BCEWithLogitsLoss()\n",
        "  dum_optim.zero_grad()\n",
        "  dum_embeddings=dum_model(dum_feats, dum_adj_dict)\n",
        "  # dum_loss=torch.sum(dum_embeddings)\n",
        "  dum_preds=dum_model.classify(dum_embeddings)\n",
        "  dum_loss=loss_func(dum_preds, dum_classes)\n",
        "  print(torchviz.make_dot(dum_loss))\n",
        "  dum_loss.backward()\n",
        "  with torch.no_grad():\n",
        "    dum_optim.step()\n",
        "    print(f'epoch {e}')\n",
        "    print()\n",
        "    # print(dum_embeddings)\n",
        "    print(dum_preds)\n",
        "    print(dum_classes)\n",
        "    print(dum_loss.item())\n",
        "    print('\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3pBnn2WsgrD"
      },
      "source": [
        "##Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECGdYA5_xwsN"
      },
      "source": [
        "### Old functions backup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB4iq_2UxyuZ"
      },
      "source": [
        "# def train_epoch_gat(model:GAT, optim, adj_dict, feats, train_loader, class_map, device):\n",
        "#   model=model.to(device)\n",
        "  \n",
        "#   loss_func=torch.nn.BCEWithLogitsLoss()\n",
        "#   optim.zero_grad()\n",
        "\n",
        "#   epoch_loss=0.\n",
        "#   epoch_score=0.\n",
        "#   for component_id in range(len(adj_matrices_comps)):\n",
        "#     batch_node_ids=[elem.item() for elem in batch_node_ids]\n",
        "#     batch_focus_ids, batch_features, index_mapping = get_batch_forward_information(model.no_iters, batch_node_ids, adj_dict, feats)\n",
        "    \n",
        "#     #model takes as forward args: node_features: torch.Tensor, index_mapping: dict, adj_dict: dict, focus_ids: list\n",
        "#     batch_preds, returned_index_mapping=model(batch_features, index_mapping, adj_dict, batch_focus_ids)\n",
        "#     batch_preds=model.classify(batch_preds)\n",
        "#     print('classified')\n",
        "\n",
        "#     #we need to recover the batch preds ordering. we know that the batch classes are ordered according to the batch_node_ids\n",
        "#     #we need to order the batch_preds accordingly as well\n",
        "#     ordered_batch_preds=torch.Tensor(batch_preds.shape)\n",
        "#     for row_index in range(len(batch_node_ids)):\n",
        "#       ordered_batch_preds[row_index]=batch_preds[returned_index_mapping[batch_node_ids[row_index]]]\n",
        "\n",
        "#     loss=loss_func(ordered_batch_preds, batch_classes)\n",
        "#     print(f'loss computed at batch {batch_no} is {loss.item()}')\n",
        "#     loss.backward()\n",
        "#     print('backward complete')\n",
        "#     with torch.no_grad():\n",
        "#       optim.step()\n",
        "#       epoch_loss+=loss.item()\n",
        "#       no_batches+=1\n",
        "#       score=get_accuracy(torch.sigmoid(ordered_batch_preds), batch_classes)\n",
        "#       epoch_score+=score\n",
        "#   return epoch_loss/no_batches, epoch_score/no_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KifbVJbMx13t"
      },
      "source": [
        "# def get_batch_forward_information(no_iters, batch_node_ids, adj_dict, feats):\n",
        "#   \"\"\"\n",
        "#   function that returns:\n",
        "#   -features of leaves nodes for all trees of nodes in batch_node_ids\n",
        "#   -a list of lists of node ids corresponding to each level of the reunion of the trees of nodes in batch_node_ids\n",
        "#   -index_mapping: a map of the actual node ids in batch_node_ids to rows of features\n",
        "\n",
        "#   feats is the entire features matrix\n",
        "#   \"\"\"\n",
        "#   #we want to get the focus nodes for the no_iters of the model\n",
        "#   #farthest first, nearest last; last focus nodes will be nodes in batch, first ones will be the ones just before leaves\n",
        "#   batch_focus_ids=[batch_node_ids]\n",
        "#   for i in range(1,no_iters):\n",
        "#     iteration_nodes=set([])\n",
        "#     for node_id in batch_focus_ids[0]:\n",
        "#       iteration_nodes=iteration_nodes | set(adj_dict[node_id])\n",
        "#     batch_focus_ids.insert(0, list(iteration_nodes))\n",
        "#     assert (len(set(batch_focus_ids[0]) & set(batch_focus_ids[1])) == len(set(batch_focus_ids[1])) ), \"Not all nodes were kept for next iteration\"\n",
        "#   for i in range(len(batch_focus_ids)):\n",
        "#     print(f'there are {len(batch_focus_ids[i])} nodes for iteration {i}')\n",
        "#   print('\\n\\n')\n",
        "#   #now on position 0 of batch_focus_ids we have the direct fathers of nodes that have just leaves; we also want the batch features\n",
        "#   #the batch features will just be the features of the leaves, because the adj_dict was constructed such that every node has itself as its' neighbor\n",
        "\n",
        "#   leaf_nodes=set([])\n",
        "#   for node_id in batch_focus_ids[0]:\n",
        "#     leaf_nodes=leaf_nodes | set(adj_dict[node_id])\n",
        "\n",
        "#   batch_features=torch.Tensor(len(leaf_nodes), model.feature_size)\n",
        "#   index_mapping={}\n",
        "#   current_row=0\n",
        "#   for node in list(leaf_nodes):\n",
        "#     batch_features[current_row]=feats[node]\n",
        "#     index_mapping[node]=current_row\n",
        "#     current_row+=1\n",
        "#   return batch_focus_ids, batch_features, index_mapping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-rBFkeovTXz"
      },
      "source": [
        "### Train loader - NO LONGER NEEDED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv4N0kYZvhQd"
      },
      "source": [
        "def make_batch_loader_gat(ids_selector: list, id_map: dict, features: np.array, class_map: dict, batch_size: int, shuffle, device):\n",
        "  \"\"\"\n",
        "  id_map: only used for obtaining the right line in features\n",
        "  ids_selector: list of ids that are in the wanted dataset\n",
        "  \"\"\"\n",
        "  out_classes=torch.FloatTensor([class_map[str(idx)] for idx in ids_selector])\n",
        "  out_classes=out_classes.to(device)\n",
        "  from torch.utils.data import TensorDataset\n",
        "  from torch.utils.data import DataLoader\n",
        "  dataset = TensorDataset(torch.tensor(ids_selector), out_classes)\n",
        "  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n",
        "  return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORPUbjqXvhQw"
      },
      "source": [
        "train_loader=make_batch_loader_gat(ids_selector=train_ids, id_map=id_map, features=feats, class_map=class_map, batch_size=300, shuffle=True, device=device)\n",
        "# val_loader=make_batch_loader_gat(ids_selector=val_ids, id_map=id_map, features=feats, class_map=class_map, batch_size=len(val_ids), shuffle=False, device=device)\n",
        "# test_loader=make_batch_loader_gat(ids_selector=test_ids, id_map=id_map, features=feats, class_map=class_map, batch_size=len(test_ids), shuffle=False, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhqUrLcFA98v"
      },
      "source": [
        "### Score function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0285AcNnAoIK"
      },
      "source": [
        "def get_accuracy(predictions, labels, probability=0.5):\n",
        "  \"\"\"\n",
        "  predictions are of the shape no_nodes x no_classes, representing probability of each node being in each class\n",
        "  labels are the same shape only binary\n",
        "\n",
        "  average='weighted' is used in f1_score because it accounts for possible class imbalances\n",
        "  \"\"\"\n",
        "  assert predictions.shape == labels.shape, \"Predictions and labels don't have same shape: \"+{predictions.shape}+\" vs. \"+{labels.shape}+\" respectively.\"\n",
        "  from sklearn.metrics import f1_score\n",
        "  cutoff=(predictions>probability).type(torch.FloatTensor)\n",
        "  score=f1_score(y_true=labels, y_pred=cutoff, average='weighted')\n",
        "  return(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SthSMYcv4nP"
      },
      "source": [
        "### Train functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FErVkapQv8M9"
      },
      "source": [
        "def train_epoch_gat(model:GAT, optim, connected_comps, feats_comps, adj_matrices_comps, \n",
        "                    components_train_indexes, components_classes_train, no_train_comps, device):\n",
        "  model=model.to(device)\n",
        "  loss_func=torch.nn.BCEWithLogitsLoss()\n",
        "  optim.zero_grad()\n",
        "\n",
        "  epoch_train_loss=0.\n",
        "\n",
        "  for component_id in range(len(connected_comps)):\n",
        "    if components_train_indexes[component_id]:\n",
        "      comp_preds=model(feats_comps[component_id], adj_matrices_comps[component_id])\n",
        "      comp_preds=model.classify(comp_preds)\n",
        "\n",
        "      comp_preds_train=comp_preds[components_train_indexes[component_id]]\n",
        "      print(comp_preds_train)\n",
        "      comp_classes_train=components_classes_train[component_id]\n",
        "      print(comp_classes_train)\n",
        "      \n",
        "      train_loss=loss_func(comp_preds_train, comp_classes_train.type(torch.FloatTensor))\n",
        "\n",
        "      train_loss.backward()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        optim.step()\n",
        "        epoch_train_loss+=train_loss.item()\n",
        "\n",
        "    \n",
        "  return epoch_train_loss/no_train_comps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8uwkbXpxKYO"
      },
      "source": [
        "def train_gat_model(model, optim, components_separated_data, no_epochs, save_identifier, model_type, save_every):\n",
        "  components_train_indexes=components_separated_data.components_train_indexes\n",
        "  components_val_indexes=components_separated_data.components_val_indexes\n",
        "  components_test_indexes=components_separated_data.components_test_indexes\n",
        "  components_classes_train=components_separated_data.components_classes_train\n",
        "  components_classes_val=components_separated_data.components_classes_val\n",
        "  components_classes_test=components_separated_data.components_classes_test\n",
        "  no_train_comps=components_separated_data.no_train_comps\n",
        "  no_val_comps=components_separated_data.no_val_comps\n",
        "  no_test_comps=components_separated_data.no_test_comps\n",
        "  for e in range(no_epochs):\n",
        "    epoch_train_loss = train_epoch_gat(model, optim, connected_comps, feats_comps, adj_matrices_comps,\n",
        "                                       components_train_indexes, components_classes_train, no_train_comps, device)\n",
        "    with torch.no_grad():\n",
        "      if e%save_every==0:\n",
        "        torch.save(model.state_dict(), basepath+model_type+save_identifier)\n",
        "     \n",
        "      #adding to total vectors for plot\n",
        "      epoch_train_score=0.\n",
        "      epoch_val_loss=0.\n",
        "      epoch_val_score=0.\n",
        "      epoch_test_loss=0.\n",
        "      epoch_test_score=0.\n",
        "      for component_id in range(len(connected_comps)):\n",
        "        comp_preds=model(feats_comps[component_id], adj_matrices_comps[component_id])\n",
        "        comp_preds=model.classify(comp_preds)\n",
        "        loss_func=torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        if components_train_indexes[component_id]:\n",
        "            comp_preds_train=comp_preds[components_train_indexes[component_id]]\n",
        "            comp_classes_train=components_classes_train[component_id]\n",
        "            train_score=get_accuracy(torch.sigmoid(comp_preds_train), comp_classes_train)\n",
        "            epoch_train_score+=train_score\n",
        "\n",
        "        \n",
        "        if components_val_indexes[component_id]:\n",
        "            comp_preds_val=comp_preds[components_val_indexes[component_id]]\n",
        "            comp_classes_val=components_classes_val[component_id]\n",
        "            val_loss=loss_func(comp_preds_val, comp_classes_val.type(torch.FloatTensor))\n",
        "            epoch_val_loss+=val_loss.item()\n",
        "            val_score=get_accuracy(torch.sigmoid(comp_preds_val), comp_classes_val)\n",
        "            epoch_val_score+=val_score\n",
        "\n",
        "        if components_test_indexes[component_id]:\n",
        "            comp_preds_test=comp_preds[components_test_indexes[component_id]]\n",
        "            comp_classes_test=components_classes_test[component_id]\n",
        "            test_loss=loss_func(comp_preds_test, comp_classes_test.type(torch.FloatTensor))\n",
        "            epoch_test_loss+=test_loss.item()\n",
        "            test_score=get_accuracy(torch.sigmoid(comp_preds_test), comp_classes_test)\n",
        "            epoch_test_score+=test_score\n",
        "\n",
        "      epoch_train_score/=no_train_comps\n",
        "      epoch_val_loss/=no_val_comps\n",
        "      epoch_val_score/=no_val_comps\n",
        "      epoch_test_loss/=no_test_comps\n",
        "      epoch_test_score/=no_test_comps\n",
        "      print(f'epoch {e} train loss {epoch_train_loss} and score {epoch_train_score}')\n",
        "      train_every_epoch_loss.append(epoch_train_loss)\n",
        "      val_every_epoch_loss.append(epoch_val_loss)\n",
        "      test_every_epoch_loss.append(epoch_test_loss)\n",
        "      train_every_epoch_score.append(epoch_train_score)\n",
        "      val_every_epoch_score.append(epoch_val_score)\n",
        "      test_every_epoch_score.append(epoch_test_score)\n",
        "      if e%save_every==0:\n",
        "        import pickle\n",
        "        with open(basepath+model_type+'_train_losses_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(train_every_epoch_loss, filehandle)\n",
        "        with open(basepath+model_type+'_val_losses_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(val_every_epoch_loss, filehandle)\n",
        "        with open(basepath+model_type+'_test_losses_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(test_every_epoch_loss, filehandle)\n",
        "        with open(basepath+model_type+'_train_scores_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(train_every_epoch_score, filehandle)\n",
        "        with open(basepath+model_type+'_val_scores_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(val_every_epoch_score, filehandle)\n",
        "        with open(basepath+model_type+'_test_scores_'+save_identifier, 'wb') as filehandle:\n",
        "          pickle.dump(test_every_epoch_score, filehandle)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXvAvPsOv6Sx"
      },
      "source": [
        "### Actual train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq0oEYZaxd_3"
      },
      "source": [
        "model=GAT(3, feats.shape[-1], 200, no_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87OzyEEoyCPw"
      },
      "source": [
        "optim=torch.optim.Adam(model.parameters(), lr=10e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7uDAvWzyI9U"
      },
      "source": [
        "no_epochs=1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeLXxIAwsmlw"
      },
      "source": [
        "save_identifier=str(model.emb_size)+'_3layer_'+'nobias'+'_intermtwiceinput'\n",
        "model_type='gat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqXX9diHxy2V"
      },
      "source": [
        "train_every_epoch_loss=[]\n",
        "val_every_epoch_loss=[]\n",
        "test_every_epoch_loss=[]\n",
        "train_every_epoch_score=[]\n",
        "val_every_epoch_score=[]\n",
        "test_every_epoch_score=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyyZQNA8sjja"
      },
      "source": [
        "train_gat_model(model, optim, components_separated_data, no_epochs, save_identifier, model_type='gat', save_every=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjCNMDhSi3FF"
      },
      "source": [
        "model.load_state_dict(torch.load(basepath+'gat'+save_identifier))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1xtq-w4e1Sy"
      },
      "source": [
        "Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32FbTe_fe2WE"
      },
      "source": [
        "plot_losses_n_scores(train_every_epoch_loss, val_every_epoch_loss, test_every_epoch_loss, 'hassh', 0,\n",
        "         train_every_epoch_score, val_every_epoch_score, test_every_epoch_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvkRKUWIezln"
      },
      "source": [
        "Load back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VoFOJZk_9wH"
      },
      "source": [
        "!ls \"$basepath\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXyPLpP3AG4L"
      },
      "source": [
        "save_identifier=\"150_2layer_nobias_intermtwiceinput\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-jbt0nejk97"
      },
      "source": [
        "import pickle\n",
        "with open(basepath+model_type+'_train_losses_'+save_identifier, 'rb') as filehandle:\n",
        "  train_every_epoch_loss=pickle.load(filehandle)\n",
        "with open(basepath+model_type+'_val_losses_'+save_identifier, 'rb') as filehandle:\n",
        "  val_every_epoch_loss=pickle.load(filehandle)\n",
        "with open(basepath+model_type+'_test_losses_'+save_identifier, 'rb') as filehandle:\n",
        "  test_every_epoch_loss=pickle.load(filehandle)\n",
        "with open(basepath+model_type+'_train_scores_'+save_identifier, 'rb') as filehandle:\n",
        "  train_every_epoch_score=pickle.load(filehandle)\n",
        "with open(basepath+model_type+'_val_scores_'+save_identifier, 'rb') as filehandle:\n",
        "  val_every_epoch_score=pickle.load(filehandle)\n",
        "with open(basepath+model_type+'_test_scores_'+save_identifier, 'rb') as filehandle:\n",
        "  test_every_epoch_score=pickle.load(filehandle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OibppoxKpdpg"
      },
      "source": [
        "print(train_every_epoch_loss)\n",
        "print(train_every_epoch_score)\n",
        "print(val_every_epoch_loss)\n",
        "print(val_every_epoch_score)\n",
        "print(test_every_epoch_loss)\n",
        "print(test_every_epoch_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kURcdoOj7nP1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}